# kakaobrain/nlp-paper-reading

## Introduction

카카오브레인 자연어처리(NLP) 팀에서 읽고 있는 논문 리뷰들을 공개하는 repository 입니다.

자연어처리 연구팀에서 읽는 논문들을 매주 업데이트 해나갈 예정입니다.

자연어처리에 대한 논문이 주가 되지만, 꼭 자연어처리 논문만을 읽지는 않습니다.

## Papers

- 2020.07.22 [Balancing Training for Multilingual NMT](notes//Balancing_Training_for_Multilingual_NMT.md)
- 2020.07.22 [TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data](notes//TaBERT.md)
- 2020.07.15 [Optimizing Data Usage via Differentiable Rewards](notes/Optimizing_Data_Usage_via_Differentiable_Rewards.md)
- 2020.07.15 [Language-agnostic BERT Sentence Embedding](notes/LaBSE.md)
- 2020.07.08 [PLATO & PLATO-2](notes/PLATO.md)
- 2020.06.17 [GPT-3 (English)](notes/GPT-3.md)
- 2020.03.25 [XLU: XNLI, XLM, XLM-R (English)](notes/XLU.md)
- 2020.02.05 [Meena (English)](notes/Meena.md)

## Contributors

- [Kyubyong Park](https://github.com/Kyubyong)
- [Jiyeon Ham](https://github.com/hammouse)
- [YJ Choe](https://github.com/yjchoe)
- [Hoon Heo](https://github.com/Huffon)

